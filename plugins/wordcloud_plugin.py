"""
ä»Šæ—¥è¯äº‘æ’ä»¶
åŠŸèƒ½ï¼šç»Ÿè®¡ä»Šæ—¥ç¾¤èŠçƒ­ç‚¹è¯ï¼Œç”Ÿæˆè¯äº‘
å‘½ä»¤ï¼š/ä»Šæ—¥è¯äº‘
ç»Ÿè®¡æ—¶é—´ï¼š0ç‚¹å¼€å§‹ï¼Œ8ç‚¹æ›´æ–°
ä½¿ç”¨jiebaåˆ†è¯ + å¤šå±‚è¿‡æ»¤æœºåˆ¶
"""

import re
from collections import Counter
from pathlib import Path
from datetime import datetime, date
from typing import Dict, List, Set
from nonebot import on_command
from nonebot.adapters.onebot.v11 import Bot, Event, GroupMessageEvent, Message, MessageSegment
from nonebot.log import logger

try:
    import jieba
    import jieba.posseg as pseg
    JIEBA_AVAILABLE = True
except ImportError:
    JIEBA_AVAILABLE = False
    logger.warning("jiebaæœªå®‰è£…ï¼Œè¯äº‘åŠŸèƒ½å°†ä½¿ç”¨ç®€å•åˆ†è¯")


# ========== åœç”¨è¯åº“ ==========

# åŸºç¡€åœç”¨è¯ï¼ˆè™šè¯ã€ä»£è¯ã€è¿è¯ç­‰ï¼‰
BASIC_STOP_WORDS = {
    "çš„", "äº†", "æ˜¯", "åœ¨", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°",
    "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™", "é‚£", "ä»–", "å¥¹", "å®ƒ", "æˆ‘ä»¬",
    "ä½ ä»¬", "ä»–ä»¬", "è¿™ä¸ª", "é‚£ä¸ª", "è¿™äº›", "é‚£äº›", "è¿™æ ·", "é‚£æ ·", "æ€ä¹ˆ", "ä»€ä¹ˆ", "å“ªé‡Œ", "ä¸ºä»€ä¹ˆ",
    "å› ä¸º", "æ‰€ä»¥", "ä½†æ˜¯", "ç„¶å", "å¦‚æœ", "è™½ç„¶", "å¯æ˜¯", "è€Œä¸”", "æˆ–è€…", "è¿˜æ˜¯", "ä¸è¿‡", "åªæ˜¯",
    "å·²ç»", "è¿˜", "å†", "åˆ", "æ‰", "å°±", "éƒ½", "åª", "ä¹Ÿ", "è¿˜æ˜¯", "æ›´", "æœ€", "éå¸¸", "ååˆ†", "ç‰¹åˆ«",
    "æ¯”è¾ƒ", "æœ‰ç‚¹", "ä¸€ç‚¹", "ä¸€äº›", "è®¸å¤š", "å¾ˆå¤š", "ä¸€ç›´", "æ€»æ˜¯", "ç»å¸¸", "æœ‰æ—¶", "å¶å°”", "ä»æ¥",
    "èƒ½", "ä¼š", "å¯ä»¥", "åº”è¯¥", "å¿…é¡»", "éœ€è¦", "æƒ³", "è¦", "å¾—", "è¿‡", "æ¥", "å»", "ç»™", "è¢«", "æŠŠ",
    "è®©", "å«", "ä½¿", "ç”±", "å¯¹", "å‘", "ä»", "ä»¥", "ä¸º", "äº", "ä¸", "åŠ", "è€Œ", "æˆ–", "ä¸”", "åˆ™",
}

# è¯­æ°”è¯ï¼ˆé‡ç‚¹è¿‡æ»¤ï¼‰
MODAL_WORDS = {
    "å•Š", "å‘€", "å“‡", "å‘¢", "å§", "å˜›", "å’¯", "å–½", "å“¦", "å“Ÿ", "å˜¿", "å—¨", "å“ˆ", "å‘µ", "å˜»", "å˜¿å˜¿",
    "å“ˆå“ˆ", "å‘µå‘µ", "å˜»å˜»", "å˜¿å˜¿", "å•¦", "å“ª", "å‘", "å˜", "å–”", "å”·", "å“", "å“å‘€", "å“å“Ÿ", "å”‰",
    "å—¯", "å—¯å—¯", "å˜›", "ä¹ˆ", "å˜", "å’§", "å–µ", "å‘œ", "å‘œå‘œ", "å˜¤", "å˜¤å˜¤", "å˜¶", "å˜¶å˜¶", "å˜¿å’»",
    "å“¼", "å“¼å“¼", "å—·", "å—·å—·", "å—·å‘œ", "å‘ƒ", "é¢", "emm", "emmm", "ummm", "å—·å‘œ", "å—¯å“¼", "å—¯å‘",
}

# ç½‘ç»œç”¨è¯­/è¡¨æƒ…è¯
INTERNET_SLANG = {
    "å“ˆå“ˆå“ˆ", "å“ˆå“ˆå“ˆå“ˆ", "å“ˆå“ˆå“ˆå“ˆå“ˆ", "å˜¿å˜¿å˜¿", "å˜»å˜»å˜»", "å‘µå‘µå‘µ", "å˜¤å˜¤å˜¤", "å‘œå‘œå‘œ", "å˜¤å˜¤å˜¤å˜¤",
    "è‰", "è‰è‰è‰", "å§æ§½", "æˆ‘å»", "æˆ‘é ", "ç‰›é€¼", "ç‰›æ‰¹", "å‰å®³", "666", "233", "2333", "23333",
    "hhh", "hhhh", "hhhhh", "www", "wwww", "wwwww", "orz", "OTZ", "å›§", "å›§rz",
}

# æ— æ„ä¹‰å•å­—ï¼ˆåªè¿‡æ»¤å•å­—ï¼Œè¯ç»„ä¸­çš„ä¸è¿‡æ»¤ï¼‰
MEANINGLESS_SINGLE = {
    "ä¸ª", "äº›", "æ ·", "ç§", "æ¬¡", "ä¸‹", "ç‚¹", "ä¼š", "èƒ½", "è¦", "æƒ³", "çœ‹", "è¯´", "åš", "å»", "æ¥",
    "ç»™", "å¯¹", "æŠŠ", "è¢«", "è®©", "å«", "ç”¨", "ä»", "åœ¨", "åˆ°", "å‘", "å¾€", "ç”±", "ä¸º", "ä»¥", "åŠ",
}

# ç‰¹æ®Šç¬¦å·å’Œæ ‡ç‚¹
PUNCTUATION = {
    "/", "ã€", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼š", "ï¼›", """, """, "'", "'", "ï¼ˆ", "ï¼‰", "[", "]", "{", "}", 
    "ã€", "ã€‘", "ã€Š", "ã€‹", "â€”", "â€¦", "Â·", "~", "@", "#", "$", "%", "^", "&", "*", "+", "=", "|", "\\",
    "<", ">", ".", ",", "!", "?", ":", ";", "'", '"', "(", ")", "-", "_", "`", "ã€", "ï¼Œ", "ã€‚",
}

# åˆå¹¶æ‰€æœ‰åœç”¨è¯
ALL_STOP_WORDS = BASIC_STOP_WORDS | MODAL_WORDS | INTERNET_SLANG | PUNCTUATION

# ä¿ç•™çš„è¯æ€§ï¼ˆjiebaåˆ†è¯ç”¨ï¼‰
KEEP_POS = {
    'n',   # åè¯
    'nr',  # äººå
    'ns',  # åœ°å
    'nt',  # æœºæ„å
    'nz',  # å…¶ä»–ä¸“å
    'v',   # åŠ¨è¯
    'vn',  # ååŠ¨è¯
    'a',   # å½¢å®¹è¯
    'an',  # åå½¢è¯
    'i',   # æˆè¯­
    'l',   # ä¹ ç”¨è¯­
    'eng', # è‹±æ–‡
}

# è‡ªå®šä¹‰è¯å…¸ï¼ˆç¾¤èŠå¸¸è§è¯ç»„ï¼‰
CUSTOM_WORDS = [
    "é’“é±¼", "æ•²æœ¨é±¼", "æœ¨é±¼", "åŠŸå¾·", "å°çŒª", "å¡”ç½—ç‰Œ", "å åœ", "è¿åŠ¿", "ä»Šæ—¥é•¿åº¦",
    "ä¿„ç½—æ–¯è½®ç›˜", "è½®ç›˜", "è¯äº‘", "äººè®¾", "å°å–µ", "çŒ«å¨˜", "ç¾¤å‹", "æœºå™¨äºº",
    "æ‰“å·¥äºº", "ç¤¾ç•œ", "æ‘¸é±¼", "åˆ’æ°´", "å†…å·", "èººå¹³", "emo", "ç ´é˜²", "ç»·ä¸ä½",
]


class WordCloudManager:
    """è¯äº‘ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        self.data_dir = Path("data/wordcloud")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.group_messages: Dict[str, List[str]] = {}
        self.group_dates: Dict[str, str] = {}
        self.group_wordclouds: Dict[str, Dict] = {}
        
        # åˆå§‹åŒ–jieba
        if JIEBA_AVAILABLE:
            # æ·»åŠ è‡ªå®šä¹‰è¯å…¸
            for word in CUSTOM_WORDS:
                jieba.add_word(word)
            logger.info("jiebaåˆ†è¯åˆå§‹åŒ–å®Œæˆï¼Œå·²åŠ è½½è‡ªå®šä¹‰è¯å…¸")
    
    def add_message(self, group_id: str, text: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å†²"""
        today = str(date.today())
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ï¼ˆæ–°çš„ä¸€å¤©ï¼‰
        if group_id not in self.group_dates or self.group_dates[group_id] != today:
            self.group_messages[group_id] = []
            self.group_dates[group_id] = today
            if group_id in self.group_wordclouds:
                del self.group_wordclouds[group_id]
        
        # æ·»åŠ æ¶ˆæ¯
        if group_id not in self.group_messages:
            self.group_messages[group_id] = []
        self.group_messages[group_id].append(text)
    
    def extract_words_jieba(self, text: str) -> List[str]:
        """ä½¿ç”¨jiebaåˆ†è¯æå–è¯è¯­ï¼ˆæ¨èï¼‰"""
        words = []
        
        # ä½¿ç”¨è¯æ€§æ ‡æ³¨åˆ†è¯
        word_pairs = pseg.cut(text)
        
        for word, pos in word_pairs:
            # å¤šå±‚è¿‡æ»¤
            # 1. è¿‡æ»¤åœç”¨è¯
            if word in ALL_STOP_WORDS:
                continue
            
            # 2. è¿‡æ»¤å•å­—æ— æ„ä¹‰è¯
            if len(word) == 1 and word in MEANINGLESS_SINGLE:
                continue
            
            # 3. åªä¿ç•™2-4å­—çš„è¯
            if len(word) < 2 or len(word) > 4:
                continue
            
            # 4. è¯æ€§è¿‡æ»¤ï¼ˆåªä¿ç•™æœ‰æ„ä¹‰çš„è¯æ€§ï¼‰
            if pos not in KEEP_POS:
                continue
            
            # 5. è¿‡æ»¤çº¯æ•°å­—å’Œçº¯è‹±æ–‡
            if word.isdigit() or word.isalpha():
                continue
            
            words.append(word)
        
        return words
    
    def extract_words_simple(self, text: str) -> List[str]:
        """ç®€å•åˆ†è¯ï¼ˆjiebaä¸å¯ç”¨æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—
        text = re.sub(r'[0-9a-zA-Z\s]+', ' ', text)
        
        words = []
        
        # æå–2-4å­—è¯ç»„
        for length in [2, 3, 4]:
            for i in range(len(text) - length + 1):
                word = text[i:i+length]
                if len(word) == length and word not in ALL_STOP_WORDS:
                    words.append(word)
        
        return words
    
    def generate_wordcloud(self, group_id: str) -> Dict:
        """ç”Ÿæˆè¯äº‘æ•°æ®"""
        if group_id not in self.group_messages:
            return {"words": [], "count": 0, "generated_at": ""}
        
        messages = self.group_messages[group_id]
        if not messages:
            return {"words": [], "count": 0, "generated_at": ""}
        
        # æå–æ‰€æœ‰è¯è¯­
        all_words = []
        for msg in messages:
            if JIEBA_AVAILABLE:
                words = self.extract_words_jieba(msg)
            else:
                words = self.extract_words_simple(msg)
            all_words.extend(words)
        
        # ç»Ÿè®¡è¯é¢‘
        word_counter = Counter(all_words)
        
        # è·å–å‰30ä¸ªé«˜é¢‘è¯
        top_words = word_counter.most_common(30)
        
        result = {
            "words": [{"word": w, "count": c} for w, c in top_words],
            "count": len(messages),
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "method": "jieba" if JIEBA_AVAILABLE else "simple"
        }
        
        # ç¼“å­˜è¯äº‘
        self.group_wordclouds[group_id] = result
        
        return result
    
    def should_update_wordcloud(self, group_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›´æ–°è¯äº‘ï¼ˆ8ç‚¹åï¼‰"""
        current_hour = datetime.now().hour
        
        # 8ç‚¹ä¹‹å‰ä¸æ›´æ–°
        if current_hour < 8:
            return False
        
        # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡
        if group_id in self.group_wordclouds:
            generated_at = self.group_wordclouds[group_id].get("generated_at", "")
            if generated_at:
                try:
                    gen_date = datetime.strptime(generated_at, "%Y-%m-%d %H:%M:%S").date()
                    if gen_date == date.today():
                        return False
                except:
                    pass
        
        return True
    
    def get_wordcloud(self, group_id: str) -> Dict:
        """è·å–è¯äº‘ï¼ˆå¦‚æœéœ€è¦åˆ™ç”Ÿæˆï¼‰"""
        if self.should_update_wordcloud(group_id):
            return self.generate_wordcloud(group_id)
        elif group_id in self.group_wordclouds:
            return self.group_wordclouds[group_id]
        else:
            return {"words": [], "count": 0, "generated_at": ""}


# å…¨å±€å®ä¾‹
wordcloud_manager = WordCloudManager()


# æ³¨å†Œå‘½ä»¤
wordcloud_cmd = on_command("ä»Šæ—¥è¯äº‘", aliases={"è¯äº‘", "çƒ­è¯"}, priority=5, block=True)


@wordcloud_cmd.handle()
async def handle_wordcloud(bot: Bot, event: Event):
    """å¤„ç†ä»Šæ—¥è¯äº‘å‘½ä»¤"""
    try:
        if not isinstance(event, GroupMessageEvent):
            await wordcloud_cmd.finish("è¯·åœ¨ç¾¤é‡Œä½¿ç”¨å–µ~")
            return
        
        group_id = str(event.group_id)
        current_hour = datetime.now().hour
        
        # 8ç‚¹ä¹‹å‰æç¤º
        if current_hour < 8:
            await wordcloud_cmd.finish("è¯äº‘è¿˜åœ¨ç”Ÿæˆä¸­å–µ~ è¯·8ç‚¹åå†æ¥çœ‹å§ï¼")
            return
        
        # è·å–è¯äº‘
        wordcloud_data = wordcloud_manager.get_wordcloud(group_id)
        
        if not wordcloud_data["words"]:
            await wordcloud_cmd.finish("ä»Šå¤©è¿˜æ²¡æœ‰è¶³å¤Ÿçš„èŠå¤©è®°å½•å–µ~")
            return
        
        # æ ¼å¼åŒ–è¾“å‡º
        method_text = "æ™ºèƒ½åˆ†è¯" if wordcloud_data.get("method") == "jieba" else "ç®€å•åˆ†è¯"
        lines = [f"ğŸ“Š ä»Šæ—¥è¯äº‘ ({method_text}) ğŸ“Š"]
        lines.append(f"ç»Ÿè®¡æ¶ˆæ¯: {wordcloud_data['count']} æ¡")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {wordcloud_data['generated_at']}")
        lines.append("")
        lines.append("ğŸ”¥ çƒ­é—¨è¯æ±‡ TOP 20:")
        
        for i, item in enumerate(wordcloud_data["words"][:20], 1):
            word = item["word"]
            count = item["count"]
            # æ ¹æ®æ’åæ˜¾ç¤ºä¸åŒçš„emoji
            if i <= 3:
                emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
            else:
                emoji = f"{i}."
            lines.append(f"{emoji} {word} ({count}æ¬¡)")
        
        await wordcloud_cmd.finish("\n".join(lines))
        
    except Exception as e:
        if "FinishedException" in str(type(e)):
            return
        logger.error(f"è¯äº‘ç”Ÿæˆå¼‚å¸¸: {e}")


# å¯¼å‡ºç»™å…¶ä»–æ¨¡å—ä½¿ç”¨
def add_message_to_wordcloud(group_id: str, text: str):
    """æ·»åŠ æ¶ˆæ¯åˆ°è¯äº‘ç»Ÿè®¡"""
    wordcloud_manager.add_message(group_id, text)
